{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import certifi\n",
    "import urllib3\n",
    "import html5lib\n",
    "import math\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sqlalchemy\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import HTML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.ttilgb.com/uiAgs03Action/openScreen.do\"\n",
    "res = requests.get(URL, 'lxml', verify=False)\n",
    "soup = BeautifulSoup(res.content, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find needed Table from web page\n",
    "*To find needed table look for children or you Soup and prettify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or children = table.findChildren()\n",
    "#for child in children:\n",
    "    #print (child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find table\n",
    "table1 = soup.find_all('tr')[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_html(str(table1))\n",
    "#print (df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter what we need\n",
    "table2 = soup.find_all(\"td\", { \"class\" : \"h23\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_html(str(table2))\n",
    "#df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#soupparser = BeautifulSoup(res.content, 'html.parser')\n",
    "#print(soupparser.prettify()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter what we need\n",
    "table = soup.find('tbody')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull data cleanly as possible, tried several loop functions to pull, \n",
    "#but with the muliple rowspans and colspans was taking to long and decided to clean with pandas\n",
    "res = []\n",
    "row = []\n",
    "\n",
    "for tr in table.find_all('tr'):\n",
    "     for td in tr.find_all('td'):\n",
    "         row.append(td.text.strip())\n",
    "     res.append(row)\n",
    "     row = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=res)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace values not needed\n",
    "df2=df.replace(to_replace= [\"TRANSACTION TYPE\"], value=' ', regex=True)\n",
    "df22=df2.replace(to_replace= [\"None\"], value=' ', regex=True)\n",
    "#df22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows of other lines\n",
    "df3=df22.drop(df.index[[0,2,3,8,9,10,11,12,13,14,15,16,17,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70]])\n",
    "#df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill down values for line\n",
    "for col in [11]:\n",
    "    df3[col] = df3[col].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix mis alignment of df bu using fillna caused by row/colspans in orginal html with if logic & finish filtering\n",
    "df3[10] = df3[10].fillna(value=df3[9])\n",
    "df3.loc[df3[1] == \"20'\",1] = df3[2] \n",
    "df3.loc[df3[2] == \"\",2] = df3[7] \n",
    "df3.loc[df3[3] == \"\",3] = df3[4] \n",
    "df4=df3.drop(columns=[0,4,5,6,7,8,9])\n",
    "#print(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change Headers for line and equip type\n",
    "df4[10] = df4[10].fillna(value=\"Type\")\n",
    "df4[11] = df4[11].fillna(value=\"Line\")\n",
    "#df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Headers\n",
    "new_header = df4.iloc[0] \n",
    "df4 = df4[1:] \n",
    "df4.columns = new_header \n",
    "#df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reorder \n",
    "col_name=\"Type\"\n",
    "first_col = df4.pop(col_name)\n",
    "df4.insert(0, col_name, first_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reorder part duex....bc I did want to learn how to do it for both columns at once\n",
    "col_name=\"Line\"\n",
    "first_col = df4.pop(col_name)\n",
    "df4.insert(0, col_name, first_col)\n",
    "#df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = df4.iloc[:, [2,3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5=df4.melt(id_vars=[\"Line\",\"Type\"], \n",
    "              var_name=\"Date\", value_name=\"TTI Status\")\n",
    "#df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df5.to_excel(r\"C:\\Users\\CodyS\\Desktop\\ETL-Project\\data.xlsx\", index = False)\n",
    "#df5.to_csv(r\"C:\\Users\\CodyS\\Desktop\\ETL-Project\\TTI.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = sqlalchemy.create_engine('postgresql://postgres:Chester8!@localhost:5432/ETL-Project')\n",
    "con = engine.connect()\n",
    "table_name = 'TTI Gate'\n",
    "df5.to_sql(table_name, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df5.to_excel(r\"C:\\Users\\CodyS\\Desktop\\ETL-Project\\data.xlsx\", index = False)\n",
    "#df5.to_csv(r\"C:\\Users\\CodyS\\Desktop\\ETL-Project\\TTI.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
